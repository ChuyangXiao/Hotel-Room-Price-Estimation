{"cells":[{"cell_type":"code","source":["## mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D1bWPGYoClS7","executionInfo":{"status":"ok","timestamp":1650318300421,"user_tz":240,"elapsed":794,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"cf79daef-4bd2-48af-e2ac-34d232d93b59"},"id":"D1bWPGYoClS7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["! pip install category_encoders"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZKjNMcKxC8UC","executionInfo":{"status":"ok","timestamp":1650318306976,"user_tz":240,"elapsed":6559,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"d4405d00-4da7-4755-8b25-aa13e4e20477"},"id":"ZKjNMcKxC8UC","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: category_encoders in /usr/local/lib/python3.7/dist-packages (2.4.0)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.0.2)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.5.2)\n","Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.3.5)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.4.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (1.21.5)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from category_encoders) (0.10.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.1.0)\n"]}]},{"cell_type":"code","execution_count":null,"id":"ad6fd7cd","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ad6fd7cd","executionInfo":{"status":"ok","timestamp":1650318313048,"user_tz":240,"elapsed":6077,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"2b4a78d6-6ea3-4e83-fa69-8b3ede9b9580"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from category_encoders import TargetEncoder\n","\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import RocCurveDisplay\n","from sklearn.metrics import precision_recall_curve\n","\n","import sklearn.metrics as sm\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_validate\n","from sklearn.model_selection import GridSearchCV\n","\n","from sklearn.dummy import DummyRegressor\n","\n","from sklearn.tree import DecisionTreeRegressor, export_graphviz\n","\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.ensemble import StackingRegressor\n","\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import OneHotEncoder\n","\n","from imblearn.under_sampling import RandomUnderSampler\n","\n","from imblearn.over_sampling import RandomOverSampler\n","from imblearn.over_sampling import SMOTE\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","from sklearn.pipeline import make_pipeline\n","from sklearn.svm import SVR\n","\n","from xgboost import XGBRegressor\n","\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation, Flatten\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"id":"51f1f1bb","metadata":{"id":"51f1f1bb"},"outputs":[],"source":["# Load the data\n","\n","df = pd.read_csv('drive/MyDrive/Hotel-Room-Price-Estimation/Data/df_final.csv',index_col = 0)\n","\n","# drop the columns that includes only one value\n","# and categorical variables that has too many values\n","df = df.drop(columns = ['israteperstay'])\n","\n","# convert to some binary features to bool\n","df['ispromo']  = (df['ispromo']== 'Y')\n","\n","df['Source']  = (df['Source']== 5)\n","\n","# Use target encoding to transform the categorical variables that have too many unique values\n","encoder = TargetEncoder()\n","df[['roomtype','city','country','ratetype','propertytype']] = encoder.fit_transform(df[['roomtype',\n","                                                                                        'city',\n","                                                                                        'country',\n","                                                                                        'ratetype',\n","                                                                                        'propertytype']], \n","                                                                                    df['price'])\n","\n","# convert the boolean terms into integers\n","df = df*1\n","\n","\n","df.to_csv('drive/MyDrive/Hotel-Room-Price-Estimation/Data/df_final_new.csv', index=False)\n","\n","# extract the feature and target from the dataset\n","X_dev = df.loc[:, df.columns != 'price']\n","y_dev = df.loc[:, df.columns == 'price']\n","\n","# train test split\n","X_train, X_test, y_train, y_test = train_test_split(X_dev, \n","                                                    y_dev, \n","                                                    test_size=0.2,  \n","                                                    random_state=123)"]},{"cell_type":"markdown","id":"45715842","metadata":{"id":"45715842"},"source":["## Baseline Regressor"]},{"cell_type":"code","execution_count":null,"id":"b12d3b83","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b12d3b83","executionInfo":{"status":"ok","timestamp":1650318324470,"user_tz":240,"elapsed":24,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"030eccd2-bd00-40a6-9d78-b06689e8336f"},"outputs":[{"output_type":"stream","name":"stdout","text":["The best training MAE is   : 63.856\n","The best testing MAE is    : 63.046\n","The training R Square is   : -0.024\n","The testing R Square is   : -0.0253\n"]}],"source":["# Create a baseline regressor to examine advanced models\n","dummy_regr = DummyRegressor(strategy=\"median\")\n","\n","dummy_regr.fit(X_train, y_train)\n","\n","train_mae_dummy = sm.mean_absolute_error(y_train, \n","                                   dummy_regr.predict(X_train))\n","\n","test_mae_dummy = sm.mean_absolute_error(y_test, \n","                                  dummy_regr.predict(X_test))\n","\n","print(f\"The best training MAE is   : {round(train_mae_dummy,3)}\")\n","print(f\"The best testing MAE is    : {round(test_mae_dummy,3)}\")\n","\n","print(f\"The training R Square is   : {round(dummy_regr.score(X_train, y_train),4)}\")\n","print(f\"The testing R Square is   : {round(dummy_regr.score(X_test, y_test),4)}\")"]},{"cell_type":"markdown","id":"946a8035","metadata":{"id":"946a8035"},"source":["## Decision Tree Regressor\n","\n","### Default Settings"]},{"cell_type":"code","execution_count":null,"id":"3d9be015","metadata":{"id":"3d9be015"},"outputs":[],"source":["# tree_para = {'max_depth':[25,50,75,100],\n","#              'max_features':[15,20,25,30]}\n","\n","# clf_dt = GridSearchCV(DecisionTreeRegressor(random_state = 123), \n","#                    tree_para, \n","#                    cv=5)\n","\n","# clf_dt.fit(X_train, y_train)\n","\n","# train_mae_dt = sm.mean_absolute_error(y_train, \n","#                                    clf_dt.best_estimator_.predict(X_train))\n","\n","# test_mae_dt = sm.mean_absolute_error(y_test, \n","#                                   clf_dt.best_estimator_.predict(X_test))\n","\n","# print(f\"The optimal parameter is   : {clf_dt.best_params_}\")\n","# print(f\"The best training MAE is   : {round(train_mae_dt,3)}\")\n","# print(f\"The best testing MAE is    : {round(test_mae_dt,3)}\")\n","\n","# print(f\"The training accuracy is   : {round(clf_dt.score(X_train, y_train)*100,4)}%\")\n","# print(f\"The testing accuracy is    : {round(clf_dt.score(X_test, y_test)*100,4)}%\")\n","\n","# The optimal parameter is   : {'max_depth': 25, 'max_features': 15}"]},{"cell_type":"code","execution_count":null,"id":"649ff8ab","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"649ff8ab","executionInfo":{"status":"ok","timestamp":1650318326856,"user_tz":240,"elapsed":2406,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"041ec5a8-efae-4eaa-c598-cc90dd4f2cfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["The best training MAE is   : 12.258\n","The best testing MAE is    : 27.416\n","The training R Square is   : 0.8915\n","The testing R Square is    : 0.0749\n"]}],"source":["dt = DecisionTreeRegressor(random_state = 123, \n","                           max_depth= 25, \n","                           max_features= 15)\n","\n","dt.fit(X_train, y_train)\n","\n","train_mae_dt = sm.mean_absolute_error(y_train, \n","                                      dt.predict(X_train))\n","\n","test_mae_dt = sm.mean_absolute_error(y_test, \n","                                     dt.predict(X_test))\n","\n","print(f\"The best training MAE is   : {round(train_mae_dt,3)}\")\n","print(f\"The best testing MAE is    : {round(test_mae_dt,3)}\")\n","\n","print(f\"The training R Square is   : {round(dt.score(X_train, y_train),4)}\")\n","print(f\"The testing R Square is    : {round(dt.score(X_test, y_test),4)}\")"]},{"cell_type":"markdown","id":"d1dedd12","metadata":{"id":"d1dedd12"},"source":["### Feature Selection\n","Consisting with the results above, we could find that there is an obvious overfitting existing in the model above (the training accuracy greatly exceeds the testing accuracy). Thus, some techniques will be implemented to avoid the overfitting."]},{"cell_type":"code","execution_count":null,"id":"ccef26a8","metadata":{"id":"ccef26a8"},"outputs":[],"source":["feature_importance = dt.feature_importances_\n","\n","k = 5\n","\n","idx = np.argpartition(feature_importance, k)\n","\n","# drop the 5 least important features\n","X_train_simplified = X_train.drop(columns = X_train.columns[idx[:k]])\n","\n","X_test_simplified = X_test.drop(columns = X_train.columns[idx[:k]])"]},{"cell_type":"code","execution_count":null,"id":"a1acabe3","metadata":{"id":"a1acabe3"},"outputs":[],"source":["# tree_para = {'max_depth':[25,50,75,100],\n","#              'max_features':[15,20,25,30]}\n","\n","# clf_dt_simp = GridSearchCV(DecisionTreeRegressor(random_state = 123), \n","#                    tree_para, \n","#                    cv=5)\n","\n","# clf_dt_simp.fit(X_train_simplified, y_train)\n","\n","# train_mae_dt_simp = sm.mean_absolute_error(y_train, \n","#                                    clf_dt_simp.best_estimator_.predict(X_train_simplified))\n","\n","# test_mae_dt_simp = sm.mean_absolute_error(y_test, \n","#                                   clf_dt_simp.best_estimator_.predict(X_test_simplified))\n","\n","# print(f\"The optimal parameter is   : {clf_dt_simp.best_params_}\")\n","# print(f\"The best training MAE is : {round(train_mae_dt_simp,3)}\")\n","# print(f\"The best testing MAE is  : {round(test_mae_dt_simp,3)}\")\n","\n","# print(f\"The training R Square is   : {round(clf_dt_simp.score(X_train_simplified , y_train)*100,4)}\")\n","# print(f\"The testing R Square is    : {round(clf_dt_simp.score(X_test_simplified, y_test)*100,4)}\")\n","\n","# The optimal parameter is   : {'bootstrap': False, 'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5}"]},{"cell_type":"code","execution_count":null,"id":"ac98aa7d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ac98aa7d","executionInfo":{"status":"ok","timestamp":1650318330688,"user_tz":240,"elapsed":3695,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"17da7508-9650-4df7-d417-85408adf8dce"},"outputs":[{"output_type":"stream","name":"stdout","text":["The best training MAE is   : 9.965\n","The best testing MAE is    : 26.725\n","The training R Square is   : 0.8958\n","The testing R Square is    : 0.0944\n"]}],"source":["dt_simp = DecisionTreeRegressor(random_state = 123, \n","                                max_depth = 25, \n","                                max_features= 15)\n","\n","dt_simp.fit(X_train_simplified, y_train)\n","\n","train_mae_dt_simp = sm.mean_absolute_error(y_train, \n","                                      dt_simp.predict(X_train_simplified))\n","\n","test_mae_dt_simp = sm.mean_absolute_error(y_test, \n","                                     dt_simp.predict(X_test_simplified))\n","\n","print(f\"The best training MAE is   : {round(train_mae_dt_simp,3)}\")\n","print(f\"The best testing MAE is    : {round(test_mae_dt_simp,3)}\")\n","\n","print(f\"The training R Square is   : {round(dt_simp.score(X_train_simplified, y_train),4)}\")\n","print(f\"The testing R Square is    : {round(dt_simp.score(X_test_simplified, y_test),4)}\")"]},{"cell_type":"markdown","id":"c9fc759b","metadata":{"id":"c9fc759b"},"source":["Thus, we could see that simply the feature selection could not solve the issue of overfitting. Thus, another accessible method to reduce the overfitting is to use an ensemble model."]},{"cell_type":"markdown","id":"04ce0bb4","metadata":{"id":"04ce0bb4"},"source":["## Random Forest Regressor\n","\n","### Default Model"]},{"cell_type":"code","execution_count":null,"id":"15adaa01","metadata":{"id":"15adaa01"},"outputs":[],"source":["# tree_para = {'max_depth':[25,50,75,100,125,150],\n","#              'max_features':['auto', 'sqrt', 'log2'],\n","#              'min_samples_split': [2, 5, 10],\n","#              'bootstrap':[True, False]\n","#              }\n","\n","# clf_rf = GridSearchCV(RandomForestRegressor(random_state = 123), \n","#                    tree_para, \n","#                    cv=5)\n","\n","# clf_rf.fit(X_train, y_train)\n","\n","# train_mae_rf = sm.mean_absolute_error(y_train, \n","#                                       clf_rf.best_estimator_.predict(X_train))\n","\n","# test_mae_rf = sm.mean_absolute_error(y_test, \n","#                                      clf_rf.best_estimator_.predict(X_test))\n","\n","# print(f\"The optimal parameter is   : {clf_rf.best_params_}\")\n","# print(f\"The best training MAE is   : {round(train_mae_rf,3)}\")\n","# print(f\"The best testing MAE is    : {round(test_mae_rf,3)}\")\n","\n","# print(f\"The training accuracy is   : {round(clf_rf.score(X_train, y_train)*100,4)}%\")\n","# print(f\"The testing accuracy is    : {round(clf_rf.score(X_test, y_test)*100,4)}%\")\n","\n","# The optimal parameter is   : {'bootstrap': False, 'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 5}"]},{"cell_type":"code","execution_count":null,"id":"ad07e237","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ad07e237","executionInfo":{"status":"ok","timestamp":1650318397966,"user_tz":240,"elapsed":67281,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"97bcda6b-f395-4dea-fff1-063dfdcfc079"},"outputs":[{"output_type":"stream","name":"stdout","text":["The best training MAE is   : 11.368\n","The best testing MAE is    : 22.871\n","The training R Square is   : 0.8499\n","The testing R Square is    : 0.2509\n"]}],"source":["# Use the complete features to train the random forest model\n","rf = RandomForestRegressor(random_state = 123, \n","                           bootstrap = False, \n","                           max_depth = 50, \n","                           max_features = 'log2',\n","                           min_samples_split = 5)\n","\n","rf.fit(X_train, y_train)\n","\n","train_mae_rf = sm.mean_absolute_error(y_train, \n","                                      rf.predict(X_train))\n","\n","test_mae_rf = sm.mean_absolute_error(y_test, \n","                                     rf.predict(X_test))\n","\n","print(f\"The best training MAE is   : {round(train_mae_rf,3)}\")\n","print(f\"The best testing MAE is    : {round(test_mae_rf,3)}\")\n","\n","print(f\"The training R Square is   : {round(rf.score(X_train, y_train),4)}\")\n","print(f\"The testing R Square is    : {round(rf.score(X_test, y_test),4)}\")"]},{"cell_type":"markdown","source":["### Gradient Boosting Regressor"],"metadata":{"id":"eT1RNCUBA36n"},"id":"eT1RNCUBA36n"},{"cell_type":"code","source":["# tree_para = {'n_estimators':[25,50,75,100],\n","#              'max_depth':[25,50,75,100],\n","#              }\n","\n","# clf_gbr = GridSearchCV(GradientBoostingRegressor(random_state = 123), \n","#                    tree_para, \n","#                    cv=5)\n","\n","# clf_gbr.fit(X_train, y_train)\n","\n","# train_mae_gbr = sm.mean_absolute_error(y_train, \n","#                                    clf_gbr.best_estimator_.predict(X_train))\n","\n","# test_mae_gbr = sm.mean_absolute_error(y_test, \n","#                                   clf_gbr.best_estimator_.predict(X_test))\n","\n","# print(f\"The optimal parameter is   : {clf_gbr.best_params_}\")\n","# print(f\"The best training MAE is : {round(train_mae_gbr,3)}\")\n","# print(f\"The best testing MAE is  : {round(test_mae_gbr,3)}\")\n","\n","# print(f\"The training accuracy is   : {round(clf_gbr.best_estimator_.score(X_train, y_train)*100,4)}%\")\n","# print(f\"The testing accuracy is    : {round(clf_gbr.best_estimator_.score(X_test, y_test)*100,4)}%\")\n","\n","# The optimal parameter is   : {'max_depth': 50, 'n_estimators': 25}"],"metadata":{"id":"-MVi05hqcu9n"},"id":"-MVi05hqcu9n","execution_count":null,"outputs":[]},{"cell_type":"code","source":["gbr = GradientBoostingRegressor(random_state = 123, \n","                           max_depth =50, \n","                           n_estimators=25)\n","\n","gbr.fit(X_train, y_train)\n","\n","train_mae_gbr = sm.mean_absolute_error(y_train, \n","                                      gbr.predict(X_train))\n","\n","test_mae_gbr = sm.mean_absolute_error(y_test, \n","                                     gbr.predict(X_test))\n","\n","print(f\"The best training MAE is   : {round(train_mae_gbr,3)}\")\n","print(f\"The best testing MAE is    : {round(test_mae_gbr,3)}\")\n","\n","print(f\"The training R Square is   : {round(gbr.score(X_train, y_train),4)}\")\n","print(f\"The testing R Square is    : {round(gbr.score(X_test, y_test),4)}\")"],"metadata":{"id":"k67QO5uv9WUy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650318465204,"user_tz":240,"elapsed":67240,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"75e93d37-06e9-4223-bc98-6714ce5504ce"},"id":"k67QO5uv9WUy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The best training MAE is   : 9.255\n","The best testing MAE is    : 25.547\n","The training R Square is   : 0.897\n","The testing R Square is    : 0.164\n"]}]},{"cell_type":"markdown","source":["### XGB Regressor"],"metadata":{"id":"AZ164snimdWr"},"id":"AZ164snimdWr"},{"cell_type":"code","execution_count":null,"id":"a10bdd8d","metadata":{"id":"a10bdd8d"},"outputs":[],"source":["# tree_para = {'n_estimators':[25,50,75,100], \n","#              'max_depth':[25,50,75,100], \n","#              }\n","\n","# clf_xgb = GridSearchCV(XGBRegressor(random_state = 123,\n","#                                 verbosity = 0), \n","#                    tree_para, \n","#                    cv=5)\n","\n","# clf_xgb.fit(X_train, y_train)\n","\n","# train_mae_xgb = sm.mean_absolute_error(y_train, \n","#                                    clf_xgb.best_estimator_.predict(X_train))\n","\n","# test_mae_xgb = sm.mean_absolute_error(y_test, \n","#                                   clf_xgb.best_estimator_.predict(X_test))\n","\n","# print(f\"The optimal parameter is   : {clf_xgb.best_params_}\")\n","# print(f\"The best training MAE is : {round(train_mae_xgb,3)}\")\n","# print(f\"The best testing MAE is  : {round(test_mae_xgb,3)}\")\n","\n","# print(f\"The training accuracy is   : {round(clf_xgb.best_estimator_.score(X_train, y_train)*100,4)}%\")\n","# print(f\"The testing accuracy is    : {round(clf_xgb.best_estimator_.score(X_test, y_test)*100,4)}%\")\n","\n","# The optimal parameter is   : {'max_depth': 25, 'n_estimators': 25}"]},{"cell_type":"code","execution_count":null,"id":"4f4937f5","metadata":{"id":"4f4937f5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650318525202,"user_tz":240,"elapsed":60002,"user":{"displayName":"Chuyang Xiao","userId":"02548350807511210968"}},"outputId":"cc41bf9c-0032-4cee-8da6-d650c2170604"},"outputs":[{"output_type":"stream","name":"stdout","text":["The best training MAE is : 16.486\n","The best testing MAE is  : 25.417\n","The training R Square is   : 0.8667\n","The testing R Square is    : 0.2534\n"]}],"source":["xgb = XGBRegressor(random_state = 123,\n","                   verbosity = 0,\n","                   max_depth = 25, \n","                   n_estimators=25\n","                   )\n","\n","xgb.fit(X_train, y_train)\n","\n","train_mae_xgb = sm.mean_absolute_error(y_train, \n","                                   xgb.predict(X_train))\n","\n","test_mae_xgb = sm.mean_absolute_error(y_test, \n","                                  xgb.predict(X_test))\n","\n","print(f\"The best training MAE is : {round(train_mae_xgb,3)}\")\n","print(f\"The best testing MAE is  : {round(test_mae_xgb,3)}\")\n","\n","print(f\"The training R Square is   : {round(xgb.score(X_train, y_train),4)}\")\n","print(f\"The testing R Square is    : {round(xgb.score(X_test, y_test),4)}\")"]},{"cell_type":"code","source":[""],"metadata":{"id":"6i4nZzvgTDD3"},"id":"6i4nZzvgTDD3","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"Initial Models.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}